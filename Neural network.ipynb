{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "num_features = 4\n",
    "sales_data = np.random.rand(num_samples, num_features)  \n",
    "sales_targets = np.random.rand(num_samples, 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(input_size, hidden_layer_size, output_size):\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, input_size], name='inputs')\n",
    "    targets = tf.placeholder(tf.float32, shape=[None, output_size], name='targets')\n",
    "\n",
    "    hidden_weights = tf.Variable(tf.random_normal([input_size, hidden_layer_size]), name='hidden_weights')\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]), name='hidden_biases')\n",
    "    \n",
    "    hidden_outputs = tf.nn.relu(tf.matmul(inputs, hidden_weights) + hidden_biases)\n",
    "\n",
    "    output_weights = tf.Variable(tf.random_normal([hidden_layer_size, output_size]), name='output_weights')\n",
    "    output_biases = tf.Variable(tf.zeros([output_size]), name='output_biases')\n",
    "    \n",
    "    outputs = tf.matmul(hidden_outputs, output_weights) + output_biases\n",
    "\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(inputs, targets, outputs):\n",
    "    loss = tf.reduce_mean(tf.square(outputs - targets), name='loss')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (?, 1)\n"
     ]
    }
   ],
   "source": [
    "input_size = 4\n",
    "hidden_layer_size = 8  \n",
    "output_size = 1\n",
    "\n",
    "inputs, targets, outputs = create_neural_network(input_size, hidden_layer_size, output_size)\n",
    "\n",
    "loss = feedforward(inputs, targets, outputs)\n",
    "\n",
    "print(\"Output shape:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'hidden_weights': np.random.randn(input_size, hidden_layer_size),\n",
    "           'output_weights': np.random.randn(hidden_layer_size, output_size)}\n",
    "biases = {'hidden_biases': np.zeros(hidden_layer_size),\n",
    "          'output_biases': np.zeros(output_size)}\n",
    "\n",
    "weight_placeholders = {tf.placeholder(tf.float32, shape=weight.shape): weight for weight in weights.values()}\n",
    "bias_placeholders = {tf.placeholder(tf.float32, shape=bias.shape): bias for bias in biases.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_neural_network(inputs, outputs, input_data, weights, biases):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())  \n",
    "        output_data = sess.run(outputs, feed_dict={inputs: input_data, **weights, **biases})\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(inputs, targets, outputs, input_data, target_data, weights, biases):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())  \n",
    "        output_data = sess.run(outputs, feed_dict={inputs: input_data, **weights, **biases})\n",
    "        loss_value = sess.run(tf.reduce_mean(tf.square(output_data - target_data)))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fout tussen voorspelde uitvoer en werkelijke uitvoer: 1.0225999597392745\n"
     ]
    }
   ],
   "source": [
    "loss_result = compute_loss(inputs, targets, outputs, sales_data, sales_targets, weight_placeholders, bias_placeholders)\n",
    "print(\"Fout tussen voorspelde uitvoer en werkelijke uitvoer:\", loss_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape na uitvoering van het netwerk: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "output_result = run_neural_network(inputs, outputs, sales_data, weight_placeholders, bias_placeholders)\n",
    "print(\"Output shape na uitvoering van het netwerk:\", output_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fout tussen voorspelde uitvoer en werkelijke uitvoer: 9.096537\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    input_feed = {inputs: sales_data, targets: sales_targets}\n",
    "    loss_result = sess.run(loss, feed_dict=input_feed)\n",
    "\n",
    "print(\"Fout tussen voorspelde uitvoer en werkelijke uitvoer:\", loss_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustment_factor = float(input())\n",
    "\n",
    "weights['hidden_weights'] *= adjustment_factor\n",
    "biases['hidden_biases'] *= adjustment_factor\n",
    "weights['output_weights'] *= adjustment_factor\n",
    "biases['output_biases'] *= adjustment_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorm van trainingsdata: (1000, 4)\n",
      "Vorm van trainingsdoelen: (1000, 1)\n",
      "Vorm van validatiedata: (200, 4)\n",
      "Vorm van validatiedoelen: (200, 1)\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = 1000\n",
    "\n",
    "train_data = np.random.rand(num_train_samples, 4) \n",
    "train_targets = np.random.rand(num_train_samples, 1) \n",
    "\n",
    "print(\"Vorm van trainingsdata:\", train_data.shape)\n",
    "print(\"Vorm van trainingsdoelen:\", train_targets.shape)\n",
    "\n",
    "\n",
    "num_validation_samples = 200\n",
    "\n",
    "validation_data = np.random.rand(num_validation_samples, 4)  \n",
    "validation_targets = np.random.rand(num_validation_samples, 1)  \n",
    "\n",
    "print(\"Vorm van validatiedata:\", validation_data.shape)\n",
    "print(\"Vorm van validatiedoelen:\", validation_targets.shape)\n",
    "\n",
    "learning_rate = 0.0025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.3407509922981262\n",
      "Epoch 2, Validation Loss: 0.26625436544418335\n",
      "Epoch 3, Validation Loss: 0.23387658596038818\n",
      "Epoch 4, Validation Loss: 0.2106522023677826\n",
      "Epoch 5, Validation Loss: 0.19508877396583557\n",
      "Epoch 6, Validation Loss: 0.1838562786579132\n",
      "Epoch 7, Validation Loss: 0.1757829636335373\n",
      "Epoch 8, Validation Loss: 0.16964374482631683\n",
      "Epoch 9, Validation Loss: 0.16434688866138458\n",
      "Epoch 10, Validation Loss: 0.15989859402179718\n",
      "Epoch 11, Validation Loss: 0.15616314113140106\n",
      "Epoch 12, Validation Loss: 0.1528511941432953\n",
      "Epoch 13, Validation Loss: 0.14976315200328827\n",
      "Epoch 14, Validation Loss: 0.14706851541996002\n",
      "Epoch 15, Validation Loss: 0.144579216837883\n",
      "Epoch 16, Validation Loss: 0.14232978224754333\n",
      "Epoch 17, Validation Loss: 0.14018358290195465\n",
      "Epoch 18, Validation Loss: 0.13820962607860565\n",
      "Epoch 19, Validation Loss: 0.13640597462654114\n",
      "Epoch 20, Validation Loss: 0.13469593226909637\n",
      "Epoch 21, Validation Loss: 0.13309097290039062\n",
      "Epoch 22, Validation Loss: 0.13156916201114655\n",
      "Epoch 23, Validation Loss: 0.13006258010864258\n",
      "Epoch 24, Validation Loss: 0.1285920888185501\n",
      "Epoch 25, Validation Loss: 0.12721015512943268\n",
      "Epoch 26, Validation Loss: 0.1258334070444107\n",
      "Epoch 27, Validation Loss: 0.12449931353330612\n",
      "Epoch 28, Validation Loss: 0.12322838604450226\n",
      "Epoch 29, Validation Loss: 0.12202940881252289\n",
      "Epoch 30, Validation Loss: 0.12085352092981339\n",
      "Epoch 31, Validation Loss: 0.11967521905899048\n",
      "Epoch 32, Validation Loss: 0.11857116967439651\n",
      "Epoch 33, Validation Loss: 0.11754770576953888\n",
      "Epoch 34, Validation Loss: 0.11652854830026627\n",
      "Epoch 35, Validation Loss: 0.11554200947284698\n",
      "Epoch 36, Validation Loss: 0.11461575329303741\n",
      "Epoch 37, Validation Loss: 0.11373045295476913\n",
      "Epoch 38, Validation Loss: 0.11286159604787827\n",
      "Epoch 39, Validation Loss: 0.11204669624567032\n",
      "Epoch 40, Validation Loss: 0.11126657575368881\n",
      "Epoch 41, Validation Loss: 0.11053573340177536\n",
      "Epoch 42, Validation Loss: 0.10983770340681076\n",
      "Epoch 43, Validation Loss: 0.10916589945554733\n",
      "Epoch 44, Validation Loss: 0.10853734612464905\n",
      "Epoch 45, Validation Loss: 0.107954241335392\n",
      "Epoch 46, Validation Loss: 0.10740111023187637\n",
      "Epoch 47, Validation Loss: 0.10687623172998428\n",
      "Epoch 48, Validation Loss: 0.10637611150741577\n",
      "Epoch 49, Validation Loss: 0.10590683668851852\n",
      "Epoch 50, Validation Loss: 0.10545329749584198\n",
      "Epoch 51, Validation Loss: 0.10503629595041275\n",
      "Epoch 52, Validation Loss: 0.10464031994342804\n",
      "Epoch 53, Validation Loss: 0.1042562872171402\n",
      "Epoch 54, Validation Loss: 0.10389601439237595\n",
      "Epoch 55, Validation Loss: 0.10354685038328171\n",
      "Epoch 56, Validation Loss: 0.10321693122386932\n",
      "Epoch 57, Validation Loss: 0.10290338844060898\n",
      "Epoch 58, Validation Loss: 0.10259491205215454\n",
      "Epoch 59, Validation Loss: 0.1022888720035553\n",
      "Epoch 60, Validation Loss: 0.10199421644210815\n",
      "Epoch 61, Validation Loss: 0.10170391201972961\n",
      "Epoch 62, Validation Loss: 0.10142436623573303\n",
      "Epoch 63, Validation Loss: 0.10114171355962753\n",
      "Epoch 64, Validation Loss: 0.10087063163518906\n",
      "Epoch 65, Validation Loss: 0.10060807317495346\n",
      "Epoch 66, Validation Loss: 0.10035544633865356\n",
      "Epoch 67, Validation Loss: 0.10011141747236252\n",
      "Epoch 68, Validation Loss: 0.09987593442201614\n",
      "Epoch 69, Validation Loss: 0.09964717924594879\n",
      "Epoch 70, Validation Loss: 0.09942728281021118\n",
      "Epoch 71, Validation Loss: 0.09921173006296158\n",
      "Epoch 72, Validation Loss: 0.09901367127895355\n",
      "Epoch 73, Validation Loss: 0.09881659597158432\n",
      "Epoch 74, Validation Loss: 0.09861766546964645\n",
      "Epoch 75, Validation Loss: 0.09842147678136826\n",
      "Epoch 76, Validation Loss: 0.09822756797075272\n",
      "Epoch 77, Validation Loss: 0.09802735596895218\n",
      "Epoch 78, Validation Loss: 0.09784664213657379\n",
      "Epoch 79, Validation Loss: 0.09768595546483994\n",
      "Epoch 80, Validation Loss: 0.09752434492111206\n",
      "Epoch 81, Validation Loss: 0.09735000878572464\n",
      "Epoch 82, Validation Loss: 0.09716789424419403\n",
      "Epoch 83, Validation Loss: 0.09698353707790375\n",
      "Epoch 84, Validation Loss: 0.09681413322687149\n",
      "Epoch 85, Validation Loss: 0.09665834158658981\n",
      "Epoch 86, Validation Loss: 0.09650710970163345\n",
      "Epoch 87, Validation Loss: 0.09635773301124573\n",
      "Epoch 88, Validation Loss: 0.09621196985244751\n",
      "Epoch 89, Validation Loss: 0.09607484936714172\n",
      "Epoch 90, Validation Loss: 0.09594154357910156\n",
      "Epoch 91, Validation Loss: 0.09581823647022247\n",
      "Epoch 92, Validation Loss: 0.09570176899433136\n",
      "Epoch 93, Validation Loss: 0.09558088332414627\n",
      "Epoch 94, Validation Loss: 0.09546573460102081\n",
      "Epoch 95, Validation Loss: 0.09534972906112671\n",
      "Epoch 96, Validation Loss: 0.0952361598610878\n",
      "Epoch 97, Validation Loss: 0.09512823075056076\n",
      "Epoch 98, Validation Loss: 0.09501826018095016\n",
      "Epoch 99, Validation Loss: 0.09490625560283661\n",
      "Epoch 100, Validation Loss: 0.09479564428329468\n",
      "Epoch 101, Validation Loss: 0.09469068795442581\n",
      "Epoch 102, Validation Loss: 0.09458491951227188\n",
      "Epoch 103, Validation Loss: 0.09448161721229553\n",
      "Epoch 104, Validation Loss: 0.0943756029009819\n",
      "Epoch 105, Validation Loss: 0.09426742792129517\n",
      "Epoch 106, Validation Loss: 0.09416402876377106\n",
      "Epoch 107, Validation Loss: 0.09406059235334396\n",
      "Epoch 108, Validation Loss: 0.09395356476306915\n",
      "Epoch 109, Validation Loss: 0.09384328126907349\n",
      "Epoch 110, Validation Loss: 0.09374044090509415\n",
      "Epoch 111, Validation Loss: 0.09363707900047302\n",
      "Epoch 112, Validation Loss: 0.0935351550579071\n",
      "Epoch 113, Validation Loss: 0.0934363529086113\n",
      "Epoch 114, Validation Loss: 0.09333448112010956\n",
      "Epoch 115, Validation Loss: 0.09322657436132431\n",
      "Epoch 116, Validation Loss: 0.0931192934513092\n",
      "Epoch 117, Validation Loss: 0.09301391243934631\n",
      "Epoch 118, Validation Loss: 0.09291046112775803\n",
      "Epoch 119, Validation Loss: 0.092808797955513\n",
      "Epoch 120, Validation Loss: 0.0927029624581337\n",
      "Epoch 121, Validation Loss: 0.09259841591119766\n",
      "Epoch 122, Validation Loss: 0.09249470382928848\n",
      "Epoch 123, Validation Loss: 0.09239105135202408\n",
      "Epoch 124, Validation Loss: 0.09228866547346115\n",
      "Epoch 125, Validation Loss: 0.09218751639127731\n",
      "Epoch 126, Validation Loss: 0.09208642691373825\n",
      "Epoch 127, Validation Loss: 0.09198614209890366\n",
      "Epoch 128, Validation Loss: 0.09188835322856903\n",
      "Epoch 129, Validation Loss: 0.09179148077964783\n",
      "Epoch 130, Validation Loss: 0.0916937068104744\n",
      "Epoch 131, Validation Loss: 0.09159605950117111\n",
      "Epoch 132, Validation Loss: 0.0914999321103096\n",
      "Epoch 133, Validation Loss: 0.09140411019325256\n",
      "Epoch 134, Validation Loss: 0.09130964428186417\n",
      "Epoch 135, Validation Loss: 0.09121602028608322\n",
      "Epoch 136, Validation Loss: 0.0911213681101799\n",
      "Epoch 137, Validation Loss: 0.09102064371109009\n",
      "Epoch 138, Validation Loss: 0.09091943502426147\n",
      "Epoch 139, Validation Loss: 0.09081901609897614\n",
      "Epoch 140, Validation Loss: 0.09072256088256836\n",
      "Epoch 141, Validation Loss: 0.09062875062227249\n",
      "Epoch 142, Validation Loss: 0.09053605049848557\n",
      "Epoch 143, Validation Loss: 0.09044274687767029\n",
      "Epoch 144, Validation Loss: 0.09034597128629684\n",
      "Epoch 145, Validation Loss: 0.09024737030267715\n",
      "Epoch 146, Validation Loss: 0.09014853835105896\n",
      "Epoch 147, Validation Loss: 0.09005162119865417\n",
      "Epoch 148, Validation Loss: 0.08995850384235382\n",
      "Epoch 149, Validation Loss: 0.08986663818359375\n",
      "Epoch 150, Validation Loss: 0.08977910876274109\n",
      "Epoch 151, Validation Loss: 0.0896938294172287\n",
      "Epoch 152, Validation Loss: 0.08961044251918793\n",
      "Epoch 153, Validation Loss: 0.08952774107456207\n",
      "Epoch 154, Validation Loss: 0.0894462987780571\n",
      "Epoch 155, Validation Loss: 0.08936598151922226\n",
      "Epoch 156, Validation Loss: 0.08927509188652039\n",
      "Epoch 157, Validation Loss: 0.08918629586696625\n",
      "Epoch 158, Validation Loss: 0.08909422904253006\n",
      "Epoch 159, Validation Loss: 0.08900219947099686\n",
      "Epoch 160, Validation Loss: 0.08892295509576797\n",
      "Epoch 161, Validation Loss: 0.08884486556053162\n",
      "Epoch 162, Validation Loss: 0.08876919746398926\n",
      "Epoch 163, Validation Loss: 0.08869685977697372\n",
      "Epoch 164, Validation Loss: 0.08862613886594772\n",
      "Epoch 165, Validation Loss: 0.08855663239955902\n",
      "Epoch 166, Validation Loss: 0.0884854719042778\n",
      "Epoch 167, Validation Loss: 0.0884159505367279\n",
      "Epoch 168, Validation Loss: 0.0883469209074974\n",
      "Epoch 169, Validation Loss: 0.08827965706586838\n",
      "Epoch 170, Validation Loss: 0.08821775764226913\n",
      "Epoch 171, Validation Loss: 0.08815748989582062\n",
      "Epoch 172, Validation Loss: 0.0880996510386467\n",
      "Epoch 173, Validation Loss: 0.08804117143154144\n",
      "Epoch 174, Validation Loss: 0.08798504620790482\n",
      "Epoch 175, Validation Loss: 0.08792693167924881\n",
      "Epoch 176, Validation Loss: 0.08786693215370178\n",
      "Epoch 177, Validation Loss: 0.08780930191278458\n",
      "Epoch 178, Validation Loss: 0.08774278312921524\n",
      "Epoch 179, Validation Loss: 0.08767641335725784\n",
      "Epoch 180, Validation Loss: 0.08760467171669006\n",
      "Epoch 181, Validation Loss: 0.0875251516699791\n",
      "Epoch 182, Validation Loss: 0.08744727820158005\n",
      "Epoch 183, Validation Loss: 0.08737114816904068\n",
      "Epoch 184, Validation Loss: 0.08729749917984009\n",
      "Epoch 185, Validation Loss: 0.0872277095913887\n",
      "Epoch 186, Validation Loss: 0.0871606096625328\n",
      "Epoch 187, Validation Loss: 0.08709685504436493\n",
      "Epoch 188, Validation Loss: 0.08703473955392838\n",
      "Epoch 189, Validation Loss: 0.08697393536567688\n",
      "Epoch 190, Validation Loss: 0.0869145616889\n",
      "Epoch 191, Validation Loss: 0.08685649931430817\n",
      "Epoch 192, Validation Loss: 0.08680177479982376\n",
      "Epoch 193, Validation Loss: 0.08674928545951843\n",
      "Epoch 194, Validation Loss: 0.08669311553239822\n",
      "Epoch 195, Validation Loss: 0.08663362264633179\n",
      "Epoch 196, Validation Loss: 0.08657621592283249\n",
      "Epoch 197, Validation Loss: 0.08651916682720184\n",
      "Epoch 198, Validation Loss: 0.08646197617053986\n",
      "Epoch 199, Validation Loss: 0.08639992773532867\n",
      "Epoch 200, Validation Loss: 0.08633588999509811\n",
      "Epoch 201, Validation Loss: 0.08627313375473022\n",
      "Epoch 202, Validation Loss: 0.08620940148830414\n",
      "Epoch 203, Validation Loss: 0.08614318817853928\n",
      "Epoch 204, Validation Loss: 0.08607906103134155\n",
      "Epoch 205, Validation Loss: 0.08601266890764236\n",
      "Epoch 206, Validation Loss: 0.08595357090234756\n",
      "Epoch 207, Validation Loss: 0.08589757233858109\n",
      "Epoch 208, Validation Loss: 0.08584325760602951\n",
      "Epoch 209, Validation Loss: 0.08579036593437195\n",
      "Epoch 210, Validation Loss: 0.08573703467845917\n",
      "Epoch 211, Validation Loss: 0.08568372577428818\n",
      "Epoch 212, Validation Loss: 0.08562949299812317\n",
      "Epoch 213, Validation Loss: 0.08556672930717468\n",
      "Epoch 214, Validation Loss: 0.08551076799631119\n",
      "Epoch 215, Validation Loss: 0.08545387536287308\n",
      "Epoch 216, Validation Loss: 0.0854000672698021\n",
      "Epoch 217, Validation Loss: 0.08534912019968033\n",
      "Epoch 218, Validation Loss: 0.08529720455408096\n",
      "Epoch 219, Validation Loss: 0.08524801582098007\n",
      "Epoch 220, Validation Loss: 0.08520054072141647\n",
      "Epoch 221, Validation Loss: 0.08514776825904846\n",
      "Epoch 222, Validation Loss: 0.08509077876806259\n",
      "Epoch 223, Validation Loss: 0.08503610640764236\n",
      "Epoch 224, Validation Loss: 0.08498174697160721\n",
      "Epoch 225, Validation Loss: 0.08492850512266159\n",
      "Epoch 226, Validation Loss: 0.08487644046545029\n",
      "Epoch 227, Validation Loss: 0.08482280373573303\n",
      "Epoch 228, Validation Loss: 0.08477537333965302\n",
      "Epoch 229, Validation Loss: 0.08472879230976105\n",
      "Epoch 230, Validation Loss: 0.08468359708786011\n",
      "Epoch 231, Validation Loss: 0.08462715893983841\n",
      "Epoch 232, Validation Loss: 0.08456937968730927\n",
      "Epoch 233, Validation Loss: 0.0845179334282875\n",
      "Epoch 234, Validation Loss: 0.08446847647428513\n",
      "Epoch 235, Validation Loss: 0.08442094922065735\n",
      "Epoch 236, Validation Loss: 0.08437465876340866\n",
      "Epoch 237, Validation Loss: 0.08432939648628235\n",
      "Epoch 238, Validation Loss: 0.08428562432527542\n",
      "Epoch 239, Validation Loss: 0.08424505591392517\n",
      "Epoch 240, Validation Loss: 0.08420617133378983\n",
      "Epoch 241, Validation Loss: 0.08416850119829178\n",
      "Epoch 242, Validation Loss: 0.08413654565811157\n",
      "Epoch 243, Validation Loss: 0.08410553634166718\n",
      "Epoch 244, Validation Loss: 0.08407527208328247\n",
      "Epoch 245, Validation Loss: 0.08404647558927536\n",
      "Epoch 246, Validation Loss: 0.08401849865913391\n",
      "Epoch 247, Validation Loss: 0.08399009704589844\n",
      "Epoch 248, Validation Loss: 0.08396320044994354\n",
      "Epoch 249, Validation Loss: 0.08393777906894684\n",
      "Epoch 250, Validation Loss: 0.08391386270523071\n",
      "Epoch 251, Validation Loss: 0.08389037847518921\n",
      "Epoch 252, Validation Loss: 0.08386767655611038\n",
      "Epoch 253, Validation Loss: 0.0838455781340599\n",
      "Epoch 254, Validation Loss: 0.08382456749677658\n",
      "Epoch 255, Validation Loss: 0.08380425721406937\n",
      "Epoch 256, Validation Loss: 0.08378437161445618\n",
      "Epoch 257, Validation Loss: 0.0837649330496788\n",
      "Epoch 258, Validation Loss: 0.08374595642089844\n",
      "Epoch 259, Validation Loss: 0.08372742682695389\n",
      "Epoch 260, Validation Loss: 0.08370930701494217\n",
      "Epoch 261, Validation Loss: 0.08369160443544388\n",
      "Epoch 262, Validation Loss: 0.08367309719324112\n",
      "Epoch 263, Validation Loss: 0.08365494012832642\n",
      "Epoch 264, Validation Loss: 0.08363719284534454\n",
      "Epoch 265, Validation Loss: 0.0836198627948761\n",
      "Epoch 266, Validation Loss: 0.08360229432582855\n",
      "Epoch 267, Validation Loss: 0.08358445763587952\n",
      "Epoch 268, Validation Loss: 0.08356697112321854\n",
      "Epoch 269, Validation Loss: 0.08354990184307098\n",
      "Epoch 270, Validation Loss: 0.08353319764137268\n",
      "Epoch 271, Validation Loss: 0.08351650834083557\n",
      "Epoch 272, Validation Loss: 0.08349918574094772\n",
      "Epoch 273, Validation Loss: 0.08348211646080017\n",
      "Epoch 274, Validation Loss: 0.08346336334943771\n",
      "Epoch 275, Validation Loss: 0.08344325423240662\n",
      "Epoch 276, Validation Loss: 0.08342236280441284\n",
      "Epoch 277, Validation Loss: 0.0833987444639206\n",
      "Epoch 278, Validation Loss: 0.0833754912018776\n",
      "Epoch 279, Validation Loss: 0.08335283398628235\n",
      "Epoch 280, Validation Loss: 0.0833321213722229\n",
      "Epoch 281, Validation Loss: 0.08331196010112762\n",
      "Epoch 282, Validation Loss: 0.08329065144062042\n",
      "Epoch 283, Validation Loss: 0.0832701101899147\n",
      "Epoch 284, Validation Loss: 0.08325162529945374\n",
      "Epoch 285, Validation Loss: 0.08323484659194946\n",
      "Epoch 286, Validation Loss: 0.08321864902973175\n",
      "Epoch 287, Validation Loss: 0.08320284634828568\n",
      "Epoch 288, Validation Loss: 0.08318862318992615\n",
      "Epoch 289, Validation Loss: 0.08317485451698303\n",
      "Epoch 290, Validation Loss: 0.08316177129745483\n",
      "Epoch 291, Validation Loss: 0.08314899355173111\n",
      "Epoch 292, Validation Loss: 0.08313659578561783\n",
      "Epoch 293, Validation Loss: 0.0831243097782135\n",
      "Epoch 294, Validation Loss: 0.08311227709054947\n",
      "Epoch 295, Validation Loss: 0.08310072124004364\n",
      "Epoch 296, Validation Loss: 0.08308939635753632\n",
      "Epoch 297, Validation Loss: 0.08307831734418869\n",
      "Epoch 298, Validation Loss: 0.08306743949651718\n",
      "Epoch 299, Validation Loss: 0.08305736631155014\n",
      "Epoch 300, Validation Loss: 0.08304718136787415\n",
      "Epoch 301, Validation Loss: 0.08303714543581009\n",
      "Epoch 302, Validation Loss: 0.08302732557058334\n",
      "Epoch 303, Validation Loss: 0.08301769196987152\n",
      "Epoch 304, Validation Loss: 0.08300924301147461\n",
      "Epoch 305, Validation Loss: 0.0830010250210762\n",
      "Epoch 306, Validation Loss: 0.08299295604228973\n",
      "Epoch 307, Validation Loss: 0.08298605680465698\n",
      "Epoch 308, Validation Loss: 0.08297941833734512\n",
      "Epoch 309, Validation Loss: 0.08297314494848251\n",
      "Epoch 310, Validation Loss: 0.08296748995780945\n",
      "Epoch 311, Validation Loss: 0.08296196162700653\n",
      "Epoch 312, Validation Loss: 0.08295533806085587\n",
      "Epoch 313, Validation Loss: 0.08294972777366638\n",
      "Epoch 314, Validation Loss: 0.08294425904750824\n",
      "Epoch 315, Validation Loss: 0.08293893188238144\n",
      "Epoch 316, Validation Loss: 0.08293340355157852\n",
      "Epoch 317, Validation Loss: 0.08292796462774277\n",
      "Epoch 318, Validation Loss: 0.08292263746261597\n",
      "Epoch 319, Validation Loss: 0.08291744440793991\n",
      "Epoch 320, Validation Loss: 0.08291233330965042\n",
      "Epoch 321, Validation Loss: 0.0829073116183281\n",
      "Epoch 322, Validation Loss: 0.08290243148803711\n",
      "Epoch 323, Validation Loss: 0.08289860934019089\n",
      "Epoch 324, Validation Loss: 0.08289489150047302\n",
      "Epoch 325, Validation Loss: 0.08289189636707306\n",
      "Epoch 326, Validation Loss: 0.08288899064064026\n",
      "Epoch 327, Validation Loss: 0.08288615942001343\n",
      "Epoch 328, Validation Loss: 0.08288338035345078\n",
      "Epoch 329, Validation Loss: 0.0828806459903717\n",
      "Epoch 330, Validation Loss: 0.08287796378135681\n",
      "Epoch 331, Validation Loss: 0.0828753113746643\n",
      "Epoch 332, Validation Loss: 0.08287271857261658\n",
      "Epoch 333, Validation Loss: 0.08287088572978973\n",
      "Epoch 334, Validation Loss: 0.08286905288696289\n",
      "Epoch 335, Validation Loss: 0.08286687731742859\n",
      "Epoch 336, Validation Loss: 0.08286537230014801\n",
      "Epoch 337, Validation Loss: 0.08286289125680923\n",
      "Epoch 338, Validation Loss: 0.08286043256521225\n",
      "Epoch 339, Validation Loss: 0.08285900205373764\n",
      "Epoch 340, Validation Loss: 0.08285658061504364\n",
      "Epoch 341, Validation Loss: 0.08285518735647202\n",
      "Epoch 342, Validation Loss: 0.082852803170681\n",
      "Epoch 343, Validation Loss: 0.08285043388605118\n",
      "Epoch 344, Validation Loss: 0.08284912258386612\n",
      "Epoch 345, Validation Loss: 0.08284680545330048\n",
      "Epoch 346, Validation Loss: 0.0828450620174408\n",
      "Epoch 347, Validation Loss: 0.08284436166286469\n",
      "Epoch 348, Validation Loss: 0.08284280449151993\n",
      "Epoch 349, Validation Loss: 0.08284125477075577\n",
      "Epoch 350, Validation Loss: 0.08284115791320801\n",
      "Epoch 351, Validation Loss: 0.08284007757902145\n",
      "Epoch 352, Validation Loss: 0.0828389897942543\n",
      "Epoch 353, Validation Loss: 0.08283893764019012\n",
      "Epoch 354, Validation Loss: 0.08283785730600357\n",
      "Epoch 355, Validation Loss: 0.08283677697181702\n",
      "Epoch 356, Validation Loss: 0.08283670246601105\n",
      "Epoch 357, Validation Loss: 0.0828355997800827\n",
      "Epoch 358, Validation Loss: 0.08283422142267227\n",
      "Epoch 359, Validation Loss: 0.08283285051584244\n",
      "Epoch 360, Validation Loss: 0.08283250033855438\n",
      "Epoch 361, Validation Loss: 0.08283112198114395\n",
      "Epoch 362, Validation Loss: 0.08283006399869919\n",
      "Epoch 363, Validation Loss: 0.08282902091741562\n",
      "Epoch 364, Validation Loss: 0.08282897621393204\n",
      "Epoch 365, Validation Loss: 0.08282791823148727\n",
      "Epoch 366, Validation Loss: 0.08282685279846191\n",
      "Epoch 367, Validation Loss: 0.08282577246427536\n",
      "Epoch 368, Validation Loss: 0.08282569795846939\n",
      "Epoch 369, Validation Loss: 0.08282461762428284\n",
      "Epoch 370, Validation Loss: 0.08282353729009628\n",
      "Epoch 371, Validation Loss: 0.08282241970300674\n",
      "Epoch 372, Validation Loss: 0.08282072097063065\n",
      "Epoch 373, Validation Loss: 0.08281960338354111\n",
      "Epoch 374, Validation Loss: 0.08281750977039337\n",
      "Epoch 375, Validation Loss: 0.08281543105840683\n",
      "Epoch 376, Validation Loss: 0.08281340450048447\n",
      "Epoch 377, Validation Loss: 0.08281141519546509\n",
      "Epoch 378, Validation Loss: 0.0828094482421875\n",
      "Epoch 379, Validation Loss: 0.08280852437019348\n",
      "Epoch 380, Validation Loss: 0.08280661702156067\n",
      "Epoch 381, Validation Loss: 0.0828041285276413\n",
      "Epoch 382, Validation Loss: 0.0828026607632637\n",
      "Epoch 383, Validation Loss: 0.08280020952224731\n",
      "Epoch 384, Validation Loss: 0.08279881626367569\n",
      "Epoch 385, Validation Loss: 0.08279742300510406\n",
      "Epoch 386, Validation Loss: 0.08279512077569962\n",
      "Epoch 387, Validation Loss: 0.08279377967119217\n",
      "Epoch 388, Validation Loss: 0.08279245346784592\n",
      "Epoch 389, Validation Loss: 0.08279077708721161\n",
      "Epoch 390, Validation Loss: 0.08278912305831909\n",
      "Epoch 391, Validation Loss: 0.08278747648000717\n",
      "Epoch 392, Validation Loss: 0.08278585225343704\n",
      "Epoch 393, Validation Loss: 0.0827842503786087\n",
      "Epoch 394, Validation Loss: 0.08278267085552216\n",
      "Epoch 395, Validation Loss: 0.0827810987830162\n",
      "Epoch 396, Validation Loss: 0.08277953416109085\n",
      "Epoch 397, Validation Loss: 0.08277949690818787\n",
      "Epoch 398, Validation Loss: 0.08277790248394012\n",
      "Epoch 399, Validation Loss: 0.08277786523103714\n",
      "Epoch 400, Validation Loss: 0.08277525007724762\n",
      "Epoch 401, Validation Loss: 0.08277522772550583\n",
      "Epoch 402, Validation Loss: 0.08277413994073868\n",
      "Epoch 403, Validation Loss: 0.08277307450771332\n",
      "Epoch 404, Validation Loss: 0.08277199417352676\n",
      "Epoch 405, Validation Loss: 0.08277034759521484\n",
      "Epoch 406, Validation Loss: 0.0827687457203865\n",
      "Epoch 407, Validation Loss: 0.08276771754026413\n",
      "Epoch 408, Validation Loss: 0.08276611566543579\n",
      "Epoch 409, Validation Loss: 0.08276510238647461\n",
      "Epoch 410, Validation Loss: 0.0827639177441597\n",
      "Epoch 411, Validation Loss: 0.08276274800300598\n",
      "Epoch 412, Validation Loss: 0.08276215195655823\n",
      "Epoch 413, Validation Loss: 0.08276095986366272\n",
      "Epoch 414, Validation Loss: 0.08276035636663437\n",
      "Epoch 415, Validation Loss: 0.08275914937257767\n",
      "Epoch 416, Validation Loss: 0.08275795727968216\n",
      "Epoch 417, Validation Loss: 0.0827573612332344\n",
      "Epoch 418, Validation Loss: 0.0827561467885971\n",
      "Epoch 419, Validation Loss: 0.0827549546957016\n",
      "Epoch 420, Validation Loss: 0.08275434374809265\n",
      "Epoch 421, Validation Loss: 0.08275313675403595\n",
      "Epoch 422, Validation Loss: 0.08275251090526581\n",
      "Epoch 423, Validation Loss: 0.0827513337135315\n",
      "Epoch 424, Validation Loss: 0.08275015652179718\n",
      "Epoch 425, Validation Loss: 0.08274956047534943\n",
      "Epoch 426, Validation Loss: 0.08274836838245392\n",
      "Epoch 427, Validation Loss: 0.0827471911907196\n",
      "Epoch 428, Validation Loss: 0.08274660259485245\n",
      "Epoch 429, Validation Loss: 0.08274540305137634\n",
      "Epoch 430, Validation Loss: 0.08274423331022263\n",
      "Epoch 431, Validation Loss: 0.08274364471435547\n",
      "Epoch 432, Validation Loss: 0.08274244517087936\n",
      "Epoch 433, Validation Loss: 0.08274128288030624\n",
      "Epoch 434, Validation Loss: 0.08274011313915253\n",
      "Epoch 435, Validation Loss: 0.08273953199386597\n",
      "Epoch 436, Validation Loss: 0.08273835480213165\n",
      "Epoch 437, Validation Loss: 0.08273719996213913\n",
      "Epoch 438, Validation Loss: 0.08273662626743317\n",
      "Epoch 439, Validation Loss: 0.08273544162511826\n",
      "Epoch 440, Validation Loss: 0.08273427188396454\n",
      "Epoch 441, Validation Loss: 0.08273370563983917\n",
      "Epoch 442, Validation Loss: 0.08273252844810486\n",
      "Epoch 443, Validation Loss: 0.08273138105869293\n",
      "Epoch 444, Validation Loss: 0.082730233669281\n",
      "Epoch 445, Validation Loss: 0.08272966742515564\n",
      "Epoch 446, Validation Loss: 0.08272849023342133\n",
      "Epoch 447, Validation Loss: 0.0827273577451706\n",
      "Epoch 448, Validation Loss: 0.08272621035575867\n",
      "Epoch 449, Validation Loss: 0.08272566646337509\n",
      "Epoch 450, Validation Loss: 0.0827244222164154\n",
      "Epoch 451, Validation Loss: 0.08272386342287064\n",
      "Epoch 452, Validation Loss: 0.08272262662649155\n",
      "Epoch 453, Validation Loss: 0.08272206038236618\n",
      "Epoch 454, Validation Loss: 0.0827208161354065\n",
      "Epoch 455, Validation Loss: 0.08271960914134979\n",
      "Epoch 456, Validation Loss: 0.08271905779838562\n",
      "Epoch 457, Validation Loss: 0.08271782100200653\n",
      "Epoch 458, Validation Loss: 0.08271728456020355\n",
      "Epoch 459, Validation Loss: 0.08271605521440506\n",
      "Epoch 460, Validation Loss: 0.08271484076976776\n",
      "Epoch 461, Validation Loss: 0.08271431177854538\n",
      "Epoch 462, Validation Loss: 0.08271308988332748\n",
      "Epoch 463, Validation Loss: 0.08271189779043198\n",
      "Epoch 464, Validation Loss: 0.0827113687992096\n",
      "Epoch 465, Validation Loss: 0.0827101618051529\n",
      "Epoch 466, Validation Loss: 0.08270964026451111\n",
      "Epoch 467, Validation Loss: 0.08270842581987381\n",
      "Epoch 468, Validation Loss: 0.0827072337269783\n",
      "Epoch 469, Validation Loss: 0.08270671963691711\n",
      "Epoch 470, Validation Loss: 0.08270552009344101\n",
      "Epoch 471, Validation Loss: 0.0827043354511261\n",
      "Epoch 472, Validation Loss: 0.08270382881164551\n",
      "Epoch 473, Validation Loss: 0.0827026292681694\n",
      "Epoch 474, Validation Loss: 0.08270145207643509\n",
      "Epoch 475, Validation Loss: 0.08270096033811569\n",
      "Epoch 476, Validation Loss: 0.08269976824522018\n",
      "Epoch 477, Validation Loss: 0.08269860595464706\n",
      "Epoch 478, Validation Loss: 0.08269843459129333\n",
      "Epoch 479, Validation Loss: 0.08269725739955902\n",
      "Epoch 480, Validation Loss: 0.0826960951089859\n",
      "Epoch 481, Validation Loss: 0.08269593864679337\n",
      "Epoch 482, Validation Loss: 0.08269476145505905\n",
      "Epoch 483, Validation Loss: 0.08269360661506653\n",
      "Epoch 484, Validation Loss: 0.0826934427022934\n",
      "Epoch 485, Validation Loss: 0.08269227296113968\n",
      "Epoch 486, Validation Loss: 0.08269111812114716\n",
      "Epoch 487, Validation Loss: 0.08269096165895462\n",
      "Epoch 488, Validation Loss: 0.0826897993683815\n",
      "Epoch 489, Validation Loss: 0.08268863707780838\n",
      "Epoch 490, Validation Loss: 0.08268848061561584\n",
      "Epoch 491, Validation Loss: 0.08268731832504272\n",
      "Epoch 492, Validation Loss: 0.0826861783862114\n",
      "Epoch 493, Validation Loss: 0.08268600702285767\n",
      "Epoch 494, Validation Loss: 0.08268485218286514\n",
      "Epoch 495, Validation Loss: 0.08268371224403381\n",
      "Epoch 496, Validation Loss: 0.08268355578184128\n",
      "Epoch 497, Validation Loss: 0.08268240094184875\n",
      "Epoch 498, Validation Loss: 0.08268125355243683\n",
      "Epoch 499, Validation Loss: 0.08268110454082489\n",
      "Epoch 500, Validation Loss: 0.08267994225025177\n",
      "Epoch 501, Validation Loss: 0.08267902582883835\n",
      "Epoch 502, Validation Loss: 0.08267808705568314\n",
      "Epoch 503, Validation Loss: 0.08267717063426971\n",
      "Epoch 504, Validation Loss: 0.0826762393116951\n",
      "Epoch 505, Validation Loss: 0.08267629891633987\n",
      "Epoch 506, Validation Loss: 0.08267534524202347\n",
      "Epoch 507, Validation Loss: 0.08267439156770706\n",
      "Epoch 508, Validation Loss: 0.08267345279455185\n",
      "Epoch 509, Validation Loss: 0.08267249912023544\n",
      "Epoch 510, Validation Loss: 0.08267156779766083\n",
      "Epoch 511, Validation Loss: 0.08267062902450562\n",
      "Epoch 512, Validation Loss: 0.0826697051525116\n",
      "Epoch 513, Validation Loss: 0.08266877382993698\n",
      "Epoch 514, Validation Loss: 0.08266884088516235\n",
      "Epoch 515, Validation Loss: 0.08266788721084595\n",
      "Epoch 516, Validation Loss: 0.08266694843769073\n",
      "Epoch 517, Validation Loss: 0.08266601711511612\n",
      "Epoch 518, Validation Loss: 0.08266507834196091\n",
      "Epoch 519, Validation Loss: 0.08266415446996689\n",
      "Epoch 520, Validation Loss: 0.08266325294971466\n",
      "Epoch 521, Validation Loss: 0.08266233652830124\n",
      "Epoch 522, Validation Loss: 0.08266142010688782\n",
      "Epoch 523, Validation Loss: 0.08266051113605499\n",
      "Epoch 524, Validation Loss: 0.08266057819128036\n",
      "Epoch 525, Validation Loss: 0.08265963196754456\n",
      "Epoch 526, Validation Loss: 0.08265870064496994\n",
      "Epoch 527, Validation Loss: 0.08265778422355652\n",
      "Epoch 528, Validation Loss: 0.08265688270330429\n",
      "Epoch 529, Validation Loss: 0.08265596628189087\n",
      "Epoch 530, Validation Loss: 0.08265504986047745\n",
      "Epoch 531, Validation Loss: 0.08265414834022522\n",
      "Epoch 532, Validation Loss: 0.08265325427055359\n",
      "Epoch 533, Validation Loss: 0.08265236765146255\n",
      "Epoch 534, Validation Loss: 0.08265145123004913\n",
      "Epoch 535, Validation Loss: 0.0826515480875969\n",
      "Epoch 536, Validation Loss: 0.08265062421560287\n",
      "Epoch 537, Validation Loss: 0.08264970779418945\n",
      "Epoch 538, Validation Loss: 0.08264882862567902\n",
      "Epoch 539, Validation Loss: 0.0826479122042656\n",
      "Epoch 540, Validation Loss: 0.08264704048633575\n",
      "Epoch 541, Validation Loss: 0.08264613896608353\n",
      "Epoch 542, Validation Loss: 0.08264525234699249\n",
      "Epoch 543, Validation Loss: 0.08264437317848206\n",
      "Epoch 544, Validation Loss: 0.08264350146055222\n",
      "Epoch 545, Validation Loss: 0.08264261484146118\n",
      "Epoch 546, Validation Loss: 0.08264175057411194\n",
      "Epoch 547, Validation Loss: 0.0826408788561821\n",
      "Epoch 548, Validation Loss: 0.08264097571372986\n",
      "Epoch 549, Validation Loss: 0.08264007419347763\n",
      "Epoch 550, Validation Loss: 0.082639180123806\n",
      "Epoch 551, Validation Loss: 0.08263830095529556\n",
      "Epoch 552, Validation Loss: 0.08263743668794632\n",
      "Epoch 553, Validation Loss: 0.08263656497001648\n",
      "Epoch 554, Validation Loss: 0.08263570070266724\n",
      "Epoch 555, Validation Loss: 0.0826348289847374\n",
      "Epoch 556, Validation Loss: 0.08263396471738815\n",
      "Epoch 557, Validation Loss: 0.08263309299945831\n",
      "Epoch 558, Validation Loss: 0.08263223618268967\n",
      "Epoch 559, Validation Loss: 0.08263138681650162\n",
      "Epoch 560, Validation Loss: 0.08263053745031357\n",
      "Epoch 561, Validation Loss: 0.08262968808412552\n",
      "Epoch 562, Validation Loss: 0.08262885361909866\n",
      "Epoch 563, Validation Loss: 0.08262801170349121\n",
      "Epoch 564, Validation Loss: 0.08262716233730316\n",
      "Epoch 565, Validation Loss: 0.0826273187994957\n",
      "Epoch 566, Validation Loss: 0.08262641727924347\n",
      "Epoch 567, Validation Loss: 0.08262558281421661\n",
      "Epoch 568, Validation Loss: 0.08262471854686737\n",
      "Epoch 569, Validation Loss: 0.08262388408184052\n",
      "Epoch 570, Validation Loss: 0.08262304216623306\n",
      "Epoch 571, Validation Loss: 0.08262220025062561\n",
      "Epoch 572, Validation Loss: 0.08262137323617935\n",
      "Epoch 573, Validation Loss: 0.0826205462217331\n",
      "Epoch 574, Validation Loss: 0.08261971175670624\n",
      "Epoch 575, Validation Loss: 0.08261890709400177\n",
      "Epoch 576, Validation Loss: 0.08261807262897491\n",
      "Epoch 577, Validation Loss: 0.08261726051568985\n",
      "Epoch 578, Validation Loss: 0.08261644095182419\n",
      "Epoch 579, Validation Loss: 0.08261564373970032\n",
      "Epoch 580, Validation Loss: 0.08261482417583466\n",
      "Epoch 581, Validation Loss: 0.08261401206254959\n",
      "Epoch 582, Validation Loss: 0.08261320739984512\n",
      "Epoch 583, Validation Loss: 0.08261241018772125\n",
      "Epoch 584, Validation Loss: 0.08261162042617798\n",
      "Epoch 585, Validation Loss: 0.08261081576347351\n",
      "Epoch 586, Validation Loss: 0.08261001855134964\n",
      "Epoch 587, Validation Loss: 0.08260923624038696\n",
      "Epoch 588, Validation Loss: 0.08260843902826309\n",
      "Epoch 589, Validation Loss: 0.08260765671730042\n",
      "Epoch 590, Validation Loss: 0.08260686695575714\n",
      "Epoch 591, Validation Loss: 0.08260608464479446\n",
      "Epoch 592, Validation Loss: 0.0826062560081482\n",
      "Epoch 593, Validation Loss: 0.08260545879602432\n",
      "Epoch 594, Validation Loss: 0.08260466903448105\n",
      "Epoch 595, Validation Loss: 0.08260388672351837\n",
      "Epoch 596, Validation Loss: 0.0826030820608139\n",
      "Epoch 597, Validation Loss: 0.08260229229927063\n",
      "Epoch 598, Validation Loss: 0.08260150998830795\n",
      "Epoch 599, Validation Loss: 0.08260069787502289\n",
      "Epoch 600, Validation Loss: 0.08259992301464081\n",
      "Epoch 601, Validation Loss: 0.08259913325309753\n",
      "Epoch 602, Validation Loss: 0.08259835839271545\n",
      "Epoch 603, Validation Loss: 0.08259758353233337\n",
      "Epoch 604, Validation Loss: 0.0825968012213707\n",
      "Epoch 605, Validation Loss: 0.08259601891040802\n",
      "Epoch 606, Validation Loss: 0.08259525150060654\n",
      "Epoch 607, Validation Loss: 0.08259448409080505\n",
      "Epoch 608, Validation Loss: 0.08259370177984238\n",
      "Epoch 609, Validation Loss: 0.0825929343700409\n",
      "Epoch 610, Validation Loss: 0.08259217441082001\n",
      "Epoch 611, Validation Loss: 0.08259139955043793\n",
      "Epoch 612, Validation Loss: 0.08259065449237823\n",
      "Epoch 613, Validation Loss: 0.08258989453315735\n",
      "Epoch 614, Validation Loss: 0.08258912712335587\n",
      "Epoch 615, Validation Loss: 0.08258838951587677\n",
      "Epoch 616, Validation Loss: 0.08258762955665588\n",
      "Epoch 617, Validation Loss: 0.0825868770480156\n",
      "Epoch 618, Validation Loss: 0.0825861394405365\n",
      "Epoch 619, Validation Loss: 0.0825853943824768\n",
      "Epoch 620, Validation Loss: 0.08258464932441711\n",
      "Epoch 621, Validation Loss: 0.08258390426635742\n",
      "Epoch 622, Validation Loss: 0.08258315920829773\n",
      "Epoch 623, Validation Loss: 0.08258242905139923\n",
      "Epoch 624, Validation Loss: 0.08258169889450073\n",
      "Epoch 625, Validation Loss: 0.08258096873760223\n",
      "Epoch 626, Validation Loss: 0.08258022367954254\n",
      "Epoch 627, Validation Loss: 0.08257950097322464\n",
      "Epoch 628, Validation Loss: 0.08257876336574554\n",
      "Epoch 629, Validation Loss: 0.08257804811000824\n",
      "Epoch 630, Validation Loss: 0.08257732540369034\n",
      "Epoch 631, Validation Loss: 0.08257660269737244\n",
      "Epoch 632, Validation Loss: 0.08257588744163513\n",
      "Epoch 633, Validation Loss: 0.08257579803466797\n",
      "Epoch 634, Validation Loss: 0.08257567137479782\n",
      "Epoch 635, Validation Loss: 0.08257552981376648\n",
      "Epoch 636, Validation Loss: 0.08257481455802917\n",
      "Epoch 637, Validation Loss: 0.08257412910461426\n",
      "Epoch 638, Validation Loss: 0.08257345110177994\n",
      "Epoch 639, Validation Loss: 0.08257278800010681\n",
      "Epoch 640, Validation Loss: 0.08257211744785309\n",
      "Epoch 641, Validation Loss: 0.08257146179676056\n",
      "Epoch 642, Validation Loss: 0.08257079869508743\n",
      "Epoch 643, Validation Loss: 0.0825701355934143\n",
      "Epoch 644, Validation Loss: 0.08256946504116058\n",
      "Epoch 645, Validation Loss: 0.08256881684064865\n",
      "Epoch 646, Validation Loss: 0.08256816118955612\n",
      "Epoch 647, Validation Loss: 0.08256751298904419\n",
      "Epoch 648, Validation Loss: 0.08256684988737106\n",
      "Epoch 649, Validation Loss: 0.08256619423627853\n",
      "Epoch 650, Validation Loss: 0.0825655460357666\n",
      "Epoch 651, Validation Loss: 0.08256489783525467\n",
      "Epoch 652, Validation Loss: 0.08256425708532333\n",
      "Epoch 653, Validation Loss: 0.0825636088848114\n",
      "Epoch 654, Validation Loss: 0.08256296068429947\n",
      "Epoch 655, Validation Loss: 0.08256233483552933\n",
      "Epoch 656, Validation Loss: 0.08256169408559799\n",
      "Epoch 657, Validation Loss: 0.08256105333566666\n",
      "Epoch 658, Validation Loss: 0.08256041258573532\n",
      "Epoch 659, Validation Loss: 0.08255978673696518\n",
      "Epoch 660, Validation Loss: 0.08255915343761444\n",
      "Epoch 661, Validation Loss: 0.0825585201382637\n",
      "Epoch 662, Validation Loss: 0.08255788683891296\n",
      "Epoch 663, Validation Loss: 0.08255726099014282\n",
      "Epoch 664, Validation Loss: 0.08255662769079208\n",
      "Epoch 665, Validation Loss: 0.08255600184202194\n",
      "Epoch 666, Validation Loss: 0.0825553685426712\n",
      "Epoch 667, Validation Loss: 0.08255474269390106\n",
      "Epoch 668, Validation Loss: 0.08255410939455032\n",
      "Epoch 669, Validation Loss: 0.08255349844694138\n",
      "Epoch 670, Validation Loss: 0.08255288004875183\n",
      "Epoch 671, Validation Loss: 0.08255273103713989\n",
      "Epoch 672, Validation Loss: 0.08255209028720856\n",
      "Epoch 673, Validation Loss: 0.08255144208669662\n",
      "Epoch 674, Validation Loss: 0.08255080878734589\n",
      "Epoch 675, Validation Loss: 0.08255017548799515\n",
      "Epoch 676, Validation Loss: 0.08255000412464142\n",
      "Epoch 677, Validation Loss: 0.08254935592412949\n",
      "Epoch 678, Validation Loss: 0.08254870772361755\n",
      "Epoch 679, Validation Loss: 0.08254852890968323\n",
      "Epoch 680, Validation Loss: 0.0825478658080101\n",
      "Epoch 681, Validation Loss: 0.08254721015691757\n",
      "Epoch 682, Validation Loss: 0.08254656195640564\n",
      "Epoch 683, Validation Loss: 0.08254636824131012\n",
      "Epoch 684, Validation Loss: 0.0825456827878952\n",
      "Epoch 685, Validation Loss: 0.08254501223564148\n",
      "Epoch 686, Validation Loss: 0.08254480361938477\n",
      "Epoch 687, Validation Loss: 0.08254411071538925\n",
      "Epoch 688, Validation Loss: 0.08254341781139374\n",
      "Epoch 689, Validation Loss: 0.08254320174455643\n",
      "Epoch 690, Validation Loss: 0.08254249393939972\n",
      "Epoch 691, Validation Loss: 0.08254179358482361\n",
      "Epoch 692, Validation Loss: 0.0825415700674057\n",
      "Epoch 693, Validation Loss: 0.08254086226224899\n",
      "Epoch 694, Validation Loss: 0.08254014700651169\n",
      "Epoch 695, Validation Loss: 0.08253992348909378\n",
      "Epoch 696, Validation Loss: 0.08253922313451767\n",
      "Epoch 697, Validation Loss: 0.08253851532936096\n",
      "Epoch 698, Validation Loss: 0.08253827691078186\n",
      "Epoch 699, Validation Loss: 0.08253755420446396\n",
      "Epoch 700, Validation Loss: 0.08253684639930725\n",
      "Epoch 701, Validation Loss: 0.08253662288188934\n",
      "Epoch 702, Validation Loss: 0.08253589272499084\n",
      "Epoch 703, Validation Loss: 0.08253564685583115\n",
      "Epoch 704, Validation Loss: 0.08253491669893265\n",
      "Epoch 705, Validation Loss: 0.08253420144319534\n",
      "Epoch 706, Validation Loss: 0.08253394067287445\n",
      "Epoch 707, Validation Loss: 0.08253321051597595\n",
      "Epoch 708, Validation Loss: 0.08253294229507446\n",
      "Epoch 709, Validation Loss: 0.08253221213817596\n",
      "Epoch 710, Validation Loss: 0.08253147453069687\n",
      "Epoch 711, Validation Loss: 0.08253121376037598\n",
      "Epoch 712, Validation Loss: 0.08253047615289688\n",
      "Epoch 713, Validation Loss: 0.08253021538257599\n",
      "Epoch 714, Validation Loss: 0.0825294703245163\n",
      "Epoch 715, Validation Loss: 0.08252920210361481\n",
      "Epoch 716, Validation Loss: 0.08252844959497452\n",
      "Epoch 717, Validation Loss: 0.08252817392349243\n",
      "Epoch 718, Validation Loss: 0.08252739906311035\n",
      "Epoch 719, Validation Loss: 0.08252658694982529\n",
      "Epoch 720, Validation Loss: 0.08252626657485962\n",
      "Epoch 721, Validation Loss: 0.08252544701099396\n",
      "Epoch 722, Validation Loss: 0.08252511918544769\n",
      "Epoch 723, Validation Loss: 0.08252427726984024\n",
      "Epoch 724, Validation Loss: 0.08252394944429398\n",
      "Epoch 725, Validation Loss: 0.08252311497926712\n",
      "Epoch 726, Validation Loss: 0.08252277225255966\n",
      "Epoch 727, Validation Loss: 0.0825219452381134\n",
      "Epoch 728, Validation Loss: 0.08252160251140594\n",
      "Epoch 729, Validation Loss: 0.08252076804637909\n",
      "Epoch 730, Validation Loss: 0.08252041041851044\n",
      "Epoch 731, Validation Loss: 0.08251957595348358\n",
      "Epoch 732, Validation Loss: 0.08251921832561493\n",
      "Epoch 733, Validation Loss: 0.08251837641000748\n",
      "Epoch 734, Validation Loss: 0.08251802623271942\n",
      "Epoch 735, Validation Loss: 0.08251718431711197\n",
      "Epoch 736, Validation Loss: 0.08251681923866272\n",
      "Epoch 737, Validation Loss: 0.08251598477363586\n",
      "Epoch 738, Validation Loss: 0.08251561969518661\n",
      "Epoch 739, Validation Loss: 0.08251478523015976\n",
      "Epoch 740, Validation Loss: 0.08251442015171051\n",
      "Epoch 741, Validation Loss: 0.08251404017210007\n",
      "Epoch 742, Validation Loss: 0.08251325786113739\n",
      "Epoch 743, Validation Loss: 0.08251296728849411\n",
      "Epoch 744, Validation Loss: 0.08251217752695084\n",
      "Epoch 745, Validation Loss: 0.08251187950372696\n",
      "Epoch 746, Validation Loss: 0.08251111954450607\n",
      "Epoch 747, Validation Loss: 0.082510806620121\n",
      "Epoch 748, Validation Loss: 0.08251003921031952\n",
      "Epoch 749, Validation Loss: 0.08250974863767624\n",
      "Epoch 750, Validation Loss: 0.08250942826271057\n",
      "Epoch 751, Validation Loss: 0.0825086385011673\n",
      "Epoch 752, Validation Loss: 0.08250833302736282\n",
      "Epoch 753, Validation Loss: 0.08250753581523895\n",
      "Epoch 754, Validation Loss: 0.08250723034143448\n",
      "Epoch 755, Validation Loss: 0.08250690251588821\n",
      "Epoch 756, Validation Loss: 0.08250611275434494\n",
      "Epoch 757, Validation Loss: 0.08250577747821808\n",
      "Epoch 758, Validation Loss: 0.0825049951672554\n",
      "Epoch 759, Validation Loss: 0.08250468224287033\n",
      "Epoch 760, Validation Loss: 0.08250436931848526\n",
      "Epoch 761, Validation Loss: 0.0825035348534584\n",
      "Epoch 762, Validation Loss: 0.08250320702791214\n",
      "Epoch 763, Validation Loss: 0.08250237256288528\n",
      "Epoch 764, Validation Loss: 0.08250203728675842\n",
      "Epoch 765, Validation Loss: 0.08250169456005096\n",
      "Epoch 766, Validation Loss: 0.0825008675456047\n",
      "Epoch 767, Validation Loss: 0.08250051736831665\n",
      "Epoch 768, Validation Loss: 0.082500159740448\n",
      "Epoch 769, Validation Loss: 0.08249934017658234\n",
      "Epoch 770, Validation Loss: 0.08249898999929428\n",
      "Epoch 771, Validation Loss: 0.08249862492084503\n",
      "Epoch 772, Validation Loss: 0.08249779045581818\n",
      "Epoch 773, Validation Loss: 0.08249743282794952\n",
      "Epoch 774, Validation Loss: 0.08249659836292267\n",
      "Epoch 775, Validation Loss: 0.08249625563621521\n",
      "Epoch 776, Validation Loss: 0.08249589800834656\n",
      "Epoch 777, Validation Loss: 0.08249504864215851\n",
      "Epoch 778, Validation Loss: 0.08249469846487045\n",
      "Epoch 779, Validation Loss: 0.0824943333864212\n",
      "Epoch 780, Validation Loss: 0.08249349892139435\n",
      "Epoch 781, Validation Loss: 0.0824931338429451\n",
      "Epoch 782, Validation Loss: 0.08249276876449585\n",
      "Epoch 783, Validation Loss: 0.08249237388372421\n",
      "Epoch 784, Validation Loss: 0.08249150961637497\n",
      "Epoch 785, Validation Loss: 0.08249112963676453\n",
      "Epoch 786, Validation Loss: 0.0824907198548317\n",
      "Epoch 787, Validation Loss: 0.08248983323574066\n",
      "Epoch 788, Validation Loss: 0.08248945325613022\n",
      "Epoch 789, Validation Loss: 0.08248904347419739\n",
      "Epoch 790, Validation Loss: 0.08248815685510635\n",
      "Epoch 791, Validation Loss: 0.08248776197433472\n",
      "Epoch 792, Validation Loss: 0.08248735219240189\n",
      "Epoch 793, Validation Loss: 0.08248695731163025\n",
      "Epoch 794, Validation Loss: 0.08248605579137802\n",
      "Epoch 795, Validation Loss: 0.08248565346002579\n",
      "Epoch 796, Validation Loss: 0.08248522132635117\n",
      "Epoch 797, Validation Loss: 0.08248430490493774\n",
      "Epoch 798, Validation Loss: 0.08248386532068253\n",
      "Epoch 799, Validation Loss: 0.08248340338468552\n",
      "Epoch 800, Validation Loss: 0.0824829638004303\n",
      "Epoch 801, Validation Loss: 0.08248203992843628\n",
      "Epoch 802, Validation Loss: 0.08248160034418106\n",
      "Epoch 803, Validation Loss: 0.08248114585876465\n",
      "Epoch 804, Validation Loss: 0.08248069882392883\n",
      "Epoch 805, Validation Loss: 0.08247976005077362\n",
      "Epoch 806, Validation Loss: 0.082479327917099\n",
      "Epoch 807, Validation Loss: 0.08247886598110199\n",
      "Epoch 808, Validation Loss: 0.08247841149568558\n",
      "Epoch 809, Validation Loss: 0.08247747272253036\n",
      "Epoch 810, Validation Loss: 0.08247702568769455\n",
      "Epoch 811, Validation Loss: 0.08247657865285873\n",
      "Epoch 812, Validation Loss: 0.08247610926628113\n",
      "Epoch 813, Validation Loss: 0.08247516304254532\n",
      "Epoch 814, Validation Loss: 0.0824747309088707\n",
      "Epoch 815, Validation Loss: 0.0824742540717125\n",
      "Epoch 816, Validation Loss: 0.08247379213571548\n",
      "Epoch 817, Validation Loss: 0.08247287571430206\n",
      "Epoch 818, Validation Loss: 0.08247242122888565\n",
      "Epoch 819, Validation Loss: 0.08247197419404984\n",
      "Epoch 820, Validation Loss: 0.08247151225805283\n",
      "Epoch 821, Validation Loss: 0.08247105777263641\n",
      "Epoch 822, Validation Loss: 0.0824701115489006\n",
      "Epoch 823, Validation Loss: 0.08246965706348419\n",
      "Epoch 824, Validation Loss: 0.08246919512748718\n",
      "Epoch 825, Validation Loss: 0.08246872574090958\n",
      "Epoch 826, Validation Loss: 0.08246826380491257\n",
      "Epoch 827, Validation Loss: 0.08246731758117676\n",
      "Epoch 828, Validation Loss: 0.08246687054634094\n",
      "Epoch 829, Validation Loss: 0.08246640115976334\n",
      "Epoch 830, Validation Loss: 0.08246593177318573\n",
      "Epoch 831, Validation Loss: 0.08246546983718872\n",
      "Epoch 832, Validation Loss: 0.08246452361345291\n",
      "Epoch 833, Validation Loss: 0.0824640691280365\n",
      "Epoch 834, Validation Loss: 0.08246360719203949\n",
      "Epoch 835, Validation Loss: 0.08246313780546188\n",
      "Epoch 836, Validation Loss: 0.08246265351772308\n",
      "Epoch 837, Validation Loss: 0.08246217668056488\n",
      "Epoch 838, Validation Loss: 0.08246122300624847\n",
      "Epoch 839, Validation Loss: 0.08246075361967087\n",
      "Epoch 840, Validation Loss: 0.08245888352394104\n",
      "Epoch 841, Validation Loss: 0.08245857059955597\n",
      "Epoch 842, Validation Loss: 0.08245813101530075\n",
      "Epoch 843, Validation Loss: 0.08245766907930374\n",
      "Epoch 844, Validation Loss: 0.08245672285556793\n",
      "Epoch 845, Validation Loss: 0.08245628327131271\n",
      "Epoch 846, Validation Loss: 0.0824558287858963\n",
      "Epoch 847, Validation Loss: 0.08245536684989929\n",
      "Epoch 848, Validation Loss: 0.08245491236448288\n",
      "Epoch 849, Validation Loss: 0.08245443552732468\n",
      "Epoch 850, Validation Loss: 0.08245395869016647\n",
      "Epoch 851, Validation Loss: 0.08245301991701126\n",
      "Epoch 852, Validation Loss: 0.08245256543159485\n",
      "Epoch 853, Validation Loss: 0.08245209604501724\n",
      "Epoch 854, Validation Loss: 0.08245161175727844\n",
      "Epoch 855, Validation Loss: 0.08245112746953964\n",
      "Epoch 856, Validation Loss: 0.08245063573122025\n",
      "Epoch 857, Validation Loss: 0.08245012909173965\n",
      "Epoch 858, Validation Loss: 0.08244776725769043\n",
      "Epoch 859, Validation Loss: 0.08244743198156357\n",
      "Epoch 860, Validation Loss: 0.08244699239730835\n",
      "Epoch 861, Validation Loss: 0.08244653791189194\n",
      "Epoch 862, Validation Loss: 0.08244606107473373\n",
      "Epoch 863, Validation Loss: 0.08244559168815613\n",
      "Epoch 864, Validation Loss: 0.08244511485099792\n",
      "Epoch 865, Validation Loss: 0.08244463056325912\n",
      "Epoch 866, Validation Loss: 0.08244413137435913\n",
      "Epoch 867, Validation Loss: 0.08244319260120392\n",
      "Epoch 868, Validation Loss: 0.08244272321462631\n",
      "Epoch 869, Validation Loss: 0.0824422538280487\n",
      "Epoch 870, Validation Loss: 0.0824417769908905\n",
      "Epoch 871, Validation Loss: 0.0824412927031517\n",
      "Epoch 872, Validation Loss: 0.0824408158659935\n",
      "Epoch 873, Validation Loss: 0.08243894577026367\n",
      "Epoch 874, Validation Loss: 0.08243861794471741\n",
      "Epoch 875, Validation Loss: 0.08243817090988159\n",
      "Epoch 876, Validation Loss: 0.08243770897388458\n",
      "Epoch 877, Validation Loss: 0.08243723213672638\n",
      "Epoch 878, Validation Loss: 0.08243628591299057\n",
      "Epoch 879, Validation Loss: 0.08243581652641296\n",
      "Epoch 880, Validation Loss: 0.08243536949157715\n",
      "Epoch 881, Validation Loss: 0.08243489265441895\n",
      "Epoch 882, Validation Loss: 0.08243442326784134\n",
      "Epoch 883, Validation Loss: 0.08243394643068314\n",
      "Epoch 884, Validation Loss: 0.08243349194526672\n",
      "Epoch 885, Validation Loss: 0.08243299275636673\n",
      "Epoch 886, Validation Loss: 0.08243114501237869\n",
      "Epoch 887, Validation Loss: 0.08243081718683243\n",
      "Epoch 888, Validation Loss: 0.08243035525083542\n",
      "Epoch 889, Validation Loss: 0.08242985606193542\n",
      "Epoch 890, Validation Loss: 0.08242937922477722\n",
      "Epoch 891, Validation Loss: 0.08242887258529663\n",
      "Epoch 892, Validation Loss: 0.08242836594581604\n",
      "Epoch 893, Validation Loss: 0.08242740482091904\n",
      "Epoch 894, Validation Loss: 0.08242692053318024\n",
      "Epoch 895, Validation Loss: 0.08242643624544144\n",
      "Epoch 896, Validation Loss: 0.08242595940828323\n",
      "Epoch 897, Validation Loss: 0.08242546021938324\n",
      "Epoch 898, Validation Loss: 0.0824236124753952\n",
      "Epoch 899, Validation Loss: 0.08242328464984894\n",
      "Epoch 900, Validation Loss: 0.08242283761501312\n",
      "Epoch 901, Validation Loss: 0.08242238312959671\n",
      "Epoch 902, Validation Loss: 0.08242189139127731\n",
      "Epoch 903, Validation Loss: 0.0824214294552803\n",
      "Epoch 904, Validation Loss: 0.0824209600687027\n",
      "Epoch 905, Validation Loss: 0.08242049813270569\n",
      "Epoch 906, Validation Loss: 0.08242003619670868\n",
      "Epoch 907, Validation Loss: 0.08241956681013107\n",
      "Epoch 908, Validation Loss: 0.08241909742355347\n",
      "Epoch 909, Validation Loss: 0.08241862058639526\n",
      "Epoch 910, Validation Loss: 0.08241676539182663\n",
      "Epoch 911, Validation Loss: 0.08241645991802216\n",
      "Epoch 912, Validation Loss: 0.08241602033376694\n",
      "Epoch 913, Validation Loss: 0.08241555839776993\n",
      "Epoch 914, Validation Loss: 0.08241508156061172\n",
      "Epoch 915, Validation Loss: 0.08241462707519531\n",
      "Epoch 916, Validation Loss: 0.0824141576886177\n",
      "Epoch 917, Validation Loss: 0.0824136957526207\n",
      "Epoch 918, Validation Loss: 0.0824132189154625\n",
      "Epoch 919, Validation Loss: 0.08241275697946548\n",
      "Epoch 920, Validation Loss: 0.08241228014230728\n",
      "Epoch 921, Validation Loss: 0.08241043239831924\n",
      "Epoch 922, Validation Loss: 0.08241011947393417\n",
      "Epoch 923, Validation Loss: 0.08240968734025955\n",
      "Epoch 924, Validation Loss: 0.08240923285484314\n",
      "Epoch 925, Validation Loss: 0.08240877091884613\n",
      "Epoch 926, Validation Loss: 0.08240831643342972\n",
      "Epoch 927, Validation Loss: 0.08240785449743271\n",
      "Epoch 928, Validation Loss: 0.0824073851108551\n",
      "Epoch 929, Validation Loss: 0.0824069231748581\n",
      "Epoch 930, Validation Loss: 0.08240645378828049\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - targets))\n",
    "\n",
    "train_operation = optimizer.minimize(loss)\n",
    "\n",
    "num_epochs = 930\n",
    "batch_size = 32\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            batch_inputs = train_data[i:i+batch_size]\n",
    "            batch_targets = train_targets[i:i+batch_size]\n",
    "            \n",
    "            _, batch_loss = sess.run([train_operation, loss], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "        \n",
    "        validation_loss = sess.run(loss, feed_dict={inputs: validation_data, targets: validation_targets})\n",
    "        print(\"Epoch {}, Validation Loss: {}\".format(epoch+1, validation_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
